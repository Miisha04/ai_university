import numpy as np

# –§—É–Ω–∫—Ü–∏—è –ª–∏–Ω–µ–π–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
def linear_function(x1, x2, x3) -> int | float:
    return x1 + 2*x2 + 3*x3

# –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ)
def forward_pass(X):
    return np.dot(X, weights) + bias

# –§—É–Ω–∫—Ü–∏—è –æ—à–∏–±–∫–∏ (MSE)
def compute_loss(y_true, y_pred):
    return np.mean((y_true - y_pred) ** 2)

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º —Å–ø—É—Å–∫–æ–º
def update_weights(X, y_true, y_pred, learning_rate):
    global weights, bias
    error = y_pred - y_true

    weights_gradient = np.dot(X.T, error) / len(X)
    bias_gradient = np.mean(error)

    weights -= learning_rate * weights_gradient
    bias -= learning_rate * bias_gradient

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
def main():
    global weights, bias

    num_experiments = 5  
    learning_rate = 0.01  
    biases_pred = []
    biases_true = []

    for exp in range(1, num_experiments + 1):
        print(f"\nüöÄ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç {exp}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –≤–µ—Å–æ–≤ –∏ –±–∏–∞—Å–∞
        weights = np.random.rand(3)
        bias = np.random.rand()

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö + —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤ [5, 5, 5]
        X_random = np.random.randint(1, 10, size=(50, 3))
        X_fixed = np.array([[5, 5, 5]])  # –û–¥–∏–Ω —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–∞—Å—Å–∏–≤
        X_train = np.vstack((X_random, X_fixed))  # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –º–∞—Å—Å–∏–≤–æ–≤

        y_train = np.array([linear_function(x1, x2, x3) for x1, x2, x3 in X_train])

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ø–æ—Ö
        epochs = np.random.randint(5000, 8000)
        print(f"üîÑ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö: {epochs}")

        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        for epoch in range(epochs):
            y_pred = forward_pass(X_train)
            loss = compute_loss(y_train, y_pred)

            update_weights(X_train, y_train, y_pred, learning_rate)

            # –í—ã–≤–æ–¥ –∫–∞–∂–¥—ã–µ 100 —ç–ø–æ—Ö
            if epoch % 100 == 0:
                print(f'Epoch {epoch}, Loss: {loss:.8f}, Weights: {weights}, Bias: {bias:.4f}')

        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        X_test = np.random.randint(1, 10, size=(2, 3))
        predictions = forward_pass(X_test)
        y_true = np.array([linear_function(x1, x2, x3) for x1, x2, x3 in X_test])

        print('üîπ –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ:', X_test)
        print('üîπ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:', predictions)
        print('üîπ –ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:', y_true)

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±–∏–∞—Å–∞
        biases_pred.append(bias)
        biases_true.append(0)  # –ï—Å–ª–∏ –≤ –ª–∏–Ω–µ–π–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –Ω–µ—Ç –±–∏–∞—Å–∞, —Ç–æ –∏—Å—Ç–∏–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 0

    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ä–µ–¥–Ω–∏—Ö –æ—à–∏–±–æ–∫
    biases_pred = np.array(biases_pred)
    biases_true = np.array(biases_true)

    mse = np.mean((biases_pred - biases_true) ** 2)
    mae = np.mean(np.abs(biases_pred - biases_true))
    mean_bias = np.mean(biases_pred)

    # –í—ã–≤–æ–¥ –±–æ–ª–µ–µ –ø–æ–Ω—è—Ç–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
    print(f"\nüìä –°—Ä–µ–¥–Ω–µ–∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –±–∏–∞—Å–∞ (MSE): {mse:.6f}")
    print(f"üìä –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ (MAE): {mae:.6f}")
    print(f"üìä –°—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±–∏–∞—Å–∞: {mean_bias:.6f}")
    print(f"üìä –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö: {mae * 100:.2f}%")

if __name__ == "__main__":
    main()
